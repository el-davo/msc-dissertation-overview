\begin{abstract}
Micro-services are currently the hot new technology for the web, they allow us to break up our otherwise monolithic architecture into much smaller more focused services. This has a lot of benefits, such as reducing system size and complexity and increasing release frequency and agility. 

There is one flaw with a micro-services architecture which I would like to attempt to address in this paper. When a particular micro service crashes it can be hard to find the root cause. Typically a developer would start their analysis by checking the logs of the failed service. This can be be both time consuming and potentially lead to misdiagnoses. The reason is that the developer is not seeing the full picture. For example the failure on service A could be a direct result of a problem that originated on service B. It is also possible that the root cause could be concealing itself in some convoluted log message that a typical developer could misinterpret. Due to the nature of micro-services encouraging continuous deployment it is also possible that a crash was as a direct result of a service deployment at a particular point in time. 

This paper will focus mainly on root cause analysis of micro-services deployed to a popular PaaS called Pivotal Cloud Foundry

\end{abstract}

\chapter{Research Context}
\lhead{\emph{Research Context}}
In my current organization we have a micro-service architecture. There are 100+ services written in multiple languages, including Node.js, Java, Python, Golang. We deploy all of our services onto Pivotal Cloud Foundry. Our current solution for log analysis is an ELK stack (Elastic-search, Log-stash and Kibana). This provides a nice interface to see the logs, however it has no opinions on where the logs come from or what information they hold. The user is on their own when trying to find a root cause to any issues.

To have an effective root cause analysis system we will need to look at certain metrics in real time. Log analysis has become a key metric over the last few years, however with the emergence of micro-services it has become more challenging in the following ways.

\begin{itemize}
  \item Logs from multiple services written in different languages. i.e. Node.js or Java
  \item Log streaming and log analysis in real time. 
  \item Store and process potentially Gigabytes of log data safely
  \item Auto-scaling
  \item Continuous deployments
\end{itemize}

There has been research done in the past which tries to solve these challenges by utilizing Big Data analysis with Apache Spark and machine learning techniques\cite{8067504}. Similarly this paper\cite{7748933} proposes to use Apache Flume and Apache Spark for real time analysis. 

While log analysis should play a valuable role in our root cause analysis, I would like to take this further and utilize some of the features that Cloud Foundry can give us. PCF has a rich public API which can give us a lot of extra data on the state of our environment, for example it is possible to interrogate the core language a service was written in by interrogating build-pack types, if we know the language it may make log analysis easier as we can in theory apply a more targeted set of rules to our analysis for that specific language. PCF can also give us current memory and disk space usage of deployed applications as well as events that took place within a certain time-frame such as starting, stopping or crashing.